{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from vrnn import utils\n",
    "from vrnn.models import VanillaModule, HillThermModule\n",
    "from vrnn.normalization import NormalizedDataset, NormalizationModule\n",
    "from vrnn.data_thermal import DatasetThermal, VoigtReussThermNormalization\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "dtype = torch.float32\n",
    "\n",
    "data_dir = utils.get_data_dir()\n",
    "\n",
    "import shutil\n",
    "import matplotlib\n",
    "plt.rcParams[\"text.usetex\"] = True if shutil.which('latex') else False\n",
    "matplotlib.rcParams[\"text.latex.preamble\"] = r\"\\usepackage{amsmath}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VRNN model\n",
    "model_norm_file = data_dir / 'Thermal2D_models/vrnn_therm2D_norm_20250121_173200.pt'\n",
    "# Vanilla model\n",
    "model_vanilla_file = data_dir / 'Thermal2D_models/vann_therm2D_20250121_202555.pt'\n",
    "\n",
    "# Load hdf5 files\n",
    "ms_file = data_dir / 'feature_engineering_thermal_2D.h5'\n",
    "print(ms_file)\n",
    "\n",
    "# Load data\n",
    "feature_idx = None\n",
    "R_range_train = [1/100., 1/50., 1/20., 1/10., 1/5., 1/2., 2, 5, 10, 20, 50, 100]\n",
    "train_data = DatasetThermal(file_name=ms_file, R_range=R_range_train, group='train_set',\n",
    "                            input_mode='descriptors', feature_idx=feature_idx, feature_key='feature_vector', ndim=2)\n",
    "\n",
    "\n",
    "R_range_val = np.concatenate([np.arange(2, 101, dtype=int), 1. / np.arange(1, 101, dtype=int)])\n",
    "val_data = DatasetThermal(file_name=ms_file, R_range=R_range_val, group='val_set',\n",
    "                          input_mode='descriptors', feature_idx=feature_idx, feature_key='feature_vector', ndim=2)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 30000\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Fetch data\n",
    "train_x, train_y = utils.get_data(train_loader, device=device, dtype=dtype)\n",
    "val_x, val_y = utils.get_data(val_loader, device=device, dtype=dtype)\n",
    "\n",
    "\n",
    "# Define normalization\n",
    "features_max = torch.cat([train_x, val_x], dim=0).max(dim=0)[0]\n",
    "features_min = torch.cat([train_x, val_x], dim=0).min(dim=0)[0]\n",
    "features_min[0],features_max[0]  = 0, 1 # Dont normalize the first feature (volume fraction)\n",
    "# features_min, features_max = None, None\n",
    "normalization = VoigtReussThermNormalization(dim=2, features_min=features_min, features_max=features_max)\n",
    "\n",
    "# Normalize data\n",
    "train_data_norm = NormalizedDataset(train_data, normalization)\n",
    "val_data_norm = NormalizedDataset(val_data, normalization)\n",
    "train_loader_norm = DataLoader(train_data_norm, batch_size=batch_size, shuffle=False)\n",
    "val_loader_norm = DataLoader(val_data_norm, batch_size=batch_size, shuffle=False)\n",
    "train_x_norm, train_y_norm = utils.get_data(train_loader_norm, device=device, dtype=dtype)\n",
    "val_x_norm, val_y_norm = utils.get_data(val_loader_norm, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vrnn.tensortools import unpack_sym\n",
    "from vrnn.losses import VoigtReussNormalizedLoss\n",
    "\n",
    "in_dim, out_dim = train_x.shape[-1], train_y.shape[-1]\n",
    "loss_fn = VoigtReussNormalizedLoss(dim=2)\n",
    "\n",
    "def compute_extended_errors(x, y, y_pred, f1_range=None):\n",
    "    \"\"\"\n",
    "    Computes mean, standard deviation, median, min, max of relative and absolute errors\n",
    "    for each phase contrast value and returns the full set of errors as well.\n",
    "\n",
    "    Args:\n",
    "    - x: Input tensor containing data features.\n",
    "    - y: Ground truth tensor.\n",
    "    - y_pred: Predicted output tensor.\n",
    "    - f1_range: Optional tuple (f1_min, f1_max) to filter data by first feature range (f1).\n",
    "\n",
    "    Returns:\n",
    "    - stats: Dictionary with extended statistics (mean, std, median, min, max) \n",
    "             for relative and absolute errors for each phase contrast.\n",
    "    - all_rel_errs: Dictionary with full relative errors for each phase contrast.\n",
    "    - all_abs_errs: Dictionary with full absolute errors for each phase contrast.\n",
    "    \"\"\"\n",
    "    # Extract unique phase contrasts\n",
    "    phase_contrasts = torch.unique(x[..., -1]).cpu().numpy()\n",
    "\n",
    "    # Dictionary to hold statistics\n",
    "    stats = {}\n",
    "    all_rel_errs = {}\n",
    "    all_abs_errs = {}\n",
    "\n",
    "    for phase_contrast in phase_contrasts:\n",
    "        # Filter by phase contrast and optional f1 range\n",
    "        mask = x[:, -1] == phase_contrast\n",
    "        if f1_range is not None:\n",
    "            f1_min, f1_max = f1_range\n",
    "            mask = mask * (x[:, 0] > f1_min) * (x[:, 0] < f1_max)\n",
    "\n",
    "        # Filtered data\n",
    "        y_filter = y[mask]\n",
    "        y_pred_filter = y_pred[mask]\n",
    "\n",
    "        # Compute absolute and relative errors\n",
    "        # abs_err = (y_filter - y_pred_filter).norm(dim=-1)\n",
    "        # rel_err = abs_err / y_filter.norm(dim=-1)\n",
    "        \n",
    "        abs_err = torch.norm(unpack_sym(y_filter, dim=2) - unpack_sym(y_pred_filter, dim=2), 'fro', dim=(1,2))\n",
    "        rel_err = abs_err / torch.norm(unpack_sym(y_filter, dim=2), 'fro', dim=(1,2))\n",
    "\n",
    "        # Store the full set of errors\n",
    "        all_rel_errs[phase_contrast.item()] = rel_err.cpu()\n",
    "        all_abs_errs[phase_contrast.item()] = abs_err.cpu()\n",
    "\n",
    "        # Store statistics\n",
    "        stats[phase_contrast.item()] = {\n",
    "            'mean_rel_err': rel_err.mean().cpu(),\n",
    "            'std_rel_err': rel_err.std().cpu(),\n",
    "            'median_rel_err': rel_err.median().cpu(),\n",
    "            'min_rel_err': rel_err.min().cpu(),\n",
    "            'max_rel_err': rel_err.max().cpu(),\n",
    "            'mean_abs_err': abs_err.mean().cpu(),\n",
    "            'std_abs_err': abs_err.std().cpu(),\n",
    "            'median_abs_err': abs_err.median().cpu(),\n",
    "            'min_abs_err': abs_err.min().cpu(),\n",
    "            'max_abs_err': abs_err.max().cpu(),\n",
    "        }\n",
    "\n",
    "    return stats, all_rel_errs, all_abs_errs\n",
    "\n",
    "# Lambda function to create the mask for a given phase contrast\n",
    "tmask = lambda contrast: train_x[:, -1] == contrast\n",
    "vmask = lambda contrast: val_x[:, -1] == contrast\n",
    "\n",
    "tnmask = lambda contrast: train_x_norm[:, -1] == contrast\n",
    "vnmask = lambda contrast: val_x_norm[:, -1] == contrast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VRNN normalized model\n",
    "\n",
    "ann_model = torch.load(model_norm_file, map_location=device, weights_only=False).to(device=device, dtype=dtype)\n",
    "model_norm = VanillaModule(ann_model).to(device=device, dtype=dtype)\n",
    "model_norm.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    train_pred_norm = model_norm(train_x_norm)\n",
    "    val_pred_norm = model_norm(val_x_norm)\n",
    "\n",
    "vrnn_norm_val_stats, vrnn_norm_val_all_rel_errs, vrnn_norm_val_all_abs_errs = compute_extended_errors(val_x_norm, val_y_norm, val_pred_norm)\n",
    "vrnn_norm_train_stats, vrnn_norm_train_all_rel_errs, vrnn_norm_train_all_abs_errs = compute_extended_errors(train_x_norm, train_y_norm, train_pred_norm)\n",
    "\n",
    "\n",
    "\n",
    "# VRNN model\n",
    "\n",
    "model = NormalizationModule(normalized_module=model_norm, normalization=normalization).to(device=device, dtype=dtype)\n",
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    train_pred = model(train_x)\n",
    "    val_pred = model(val_x)\n",
    "\n",
    "rel_err_train = torch.norm(unpack_sym(train_y, dim=2) - unpack_sym(train_pred, dim=2), 'fro', dim=(1,2)) / torch.norm(unpack_sym(train_y, dim=2), 'fro', dim=(1,2))\n",
    "rel_err_val = torch.norm(unpack_sym(val_y, dim=2) - unpack_sym(val_pred, dim=2), 'fro', dim=(1,2)) / torch.norm(unpack_sym(val_y, dim=2), 'fro', dim=(1,2))\n",
    "\n",
    "print(f'median rel. error (training) {rel_err_train.median():.4f}, '\n",
    "      f'median rel. error (validation) {rel_err_val.median():.4f}')\n",
    "print(f'mean rel. error (training) {rel_err_train.mean():.4f}, '\n",
    "      f'mean rel. error (validation) {rel_err_val.mean():.4f}')\n",
    "print(f'max rel. error (training) {rel_err_train.max():.4f}, '\n",
    "      f'max rel. error (validation) {rel_err_val.max():.4f}')\n",
    "\n",
    "vrnn_val_stats, vrnn_val_all_rel_errs, vrnn_val_all_abs_errs = compute_extended_errors(val_x, val_y, val_pred)\n",
    "vrnn_train_stats, vrnn_train_all_rel_errs, vrnn_train_all_abs_errs = compute_extended_errors(train_x, train_y, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla ANN model\n",
    "\n",
    "ann_model = torch.load(model_vanilla_file, map_location=device, weights_only=False).to(device=device, dtype=dtype)\n",
    "model_vanilla = VanillaModule(ann_model).to(device=device, dtype=dtype)\n",
    "model_vanilla.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    train_pred_vanilla = model_vanilla(train_x)\n",
    "    val_pred_vanilla = model_vanilla(val_x)\n",
    "\n",
    "rel_err_train_vanilla = torch.norm(unpack_sym(train_y, dim=2) - unpack_sym(train_pred_vanilla, dim=2), 'fro', dim=(1,2)) / torch.norm(unpack_sym(train_y, dim=2), 'fro', dim=(1,2))\n",
    "rel_err_val_vanilla = torch.norm(unpack_sym(val_y, dim=2) - unpack_sym(val_pred_vanilla, dim=2), 'fro', dim=(1,2)) / torch.norm(unpack_sym(val_y, dim=2), 'fro', dim=(1,2))\n",
    "\n",
    "print(f'median rel. error (training, Vanilla) {rel_err_train_vanilla.median():.4f}, '\n",
    "      f'median rel. error (validation, Vanilla) {rel_err_val_vanilla.median():.4f}')\n",
    "print(f'mean rel. error (training, Vanilla) {rel_err_train_vanilla.mean():.4f}, '\n",
    "      f'mean rel. error (validation, Vanilla) {rel_err_val_vanilla.mean():.4f}')\n",
    "print(f'max rel. error (training, Vanilla) {rel_err_train_vanilla.max():.4f}, '\n",
    "      f'max rel. error (validation, Vanilla) {rel_err_val_vanilla.max():.4f}')\n",
    "\n",
    "vanilla_val_stats, vanilla_val_all_rel_errs, vanilla_val_all_abs_errs = compute_extended_errors(val_x, val_y, val_pred_vanilla)\n",
    "vanilla_train_stats, vanilla_train_all_rel_errs, vanilla_train_all_abs_errs = compute_extended_errors(train_x, train_y, train_pred_vanilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hill model\n",
    "\n",
    "model_hill = HillThermModule(dim=2)\n",
    "model_hill.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    train_hill = model_hill(train_x)\n",
    "    val_hill = model_hill(val_x)\n",
    "\n",
    "rel_err_train_hill = torch.norm(unpack_sym(train_y, dim=2) - unpack_sym(train_hill, dim=2), 'fro', dim=(1,2)) / torch.norm(unpack_sym(train_y, dim=2), 'fro', dim=(1,2))\n",
    "rel_err_val_hill = torch.norm(unpack_sym(val_y, dim=2) - unpack_sym(val_hill, dim=2), 'fro', dim=(1,2)) / torch.norm(unpack_sym(val_y, dim=2), 'fro', dim=(1,2))\n",
    "\n",
    "print(f'median rel. error (training, Hill) {rel_err_train_hill.median():.4f}, '\n",
    "      f'median rel. error (validation, Hill) {rel_err_val_hill.median():.4f}')\n",
    "print(f'mean rel. error (training, Hill) {rel_err_train_hill.mean():.4f}, '\n",
    "      f'mean rel. error (validation, Hill) {rel_err_val_hill.mean():.4f}')\n",
    "print(f'max rel. error (training, Hill) {rel_err_train_hill.max():.4f}, '\n",
    "      f'max rel. error (validation, Hill) {rel_err_val_hill.max():.4f}')\n",
    "\n",
    "hill_val_stats, hill_val_all_rel_errs, hill_val_all_abs_errs = compute_extended_errors(val_x, val_y, val_hill)\n",
    "hill_train_stats, hill_train_all_rel_errs, hill_train_all_abs_errs = compute_extended_errors(train_x, train_y, train_hill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 8\n",
    "plt.rcParams.update({'font.size': fontsize})\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "plt.rcParams.update({\n",
    "    'font.size': fontsize,\n",
    "})\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def plot_stacked_kde(all_errors, ax, min_variance_threshold=1e-6, fontsize=20):\n",
    "    phase_contrasts = sorted(all_errors.keys())\n",
    "    all_error_values = np.concatenate([all_errors[pc].numpy() * 100 for pc in phase_contrasts])\n",
    "    global_min, global_max = np.min(all_error_values), np.max(all_error_values)\n",
    "    error_grid = np.linspace(global_min, global_max, 1000)\n",
    "    \n",
    "    pc_vals_list, densities_list = [], []\n",
    "    for pc in phase_contrasts:\n",
    "        error_values = all_errors[pc].numpy() * 100\n",
    "        if np.var(error_values) < min_variance_threshold:\n",
    "            print(f\"Skipping phase contrast {pc} due to low variance\")\n",
    "            continue\n",
    "        density = gaussian_kde(error_values)(error_grid)\n",
    "        density /= np.max(density)  # normalize\n",
    "        pc_vals_list.append(np.full_like(error_grid, pc))\n",
    "        densities_list.append(density)\n",
    "    \n",
    "    if len(pc_vals_list) == 0:\n",
    "        print(\"No valid phase contrasts to plot\")\n",
    "        return ax\n",
    "\n",
    "    valid_pcs = np.array([arr[0] for arr in pc_vals_list])\n",
    "    Z = np.array(densities_list)\n",
    "    X, Y = np.meshgrid(valid_pcs, error_grid)\n",
    "    \n",
    "    c = ax.pcolormesh(X, Y, Z.T, cmap='Blues', shading='auto')\n",
    "    # cb = ax.figure.colorbar(c, ax=ax)\n",
    "    # cb.ax.tick_params(labelsize=fontsize)\n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel(fr\"Phase contrast $R \\;[-]$\", fontsize=fontsize)\n",
    "    ax.set_ylabel(fr\"Relative Frobenius error $[\\%]$\", fontsize=fontsize)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return ax\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(6.3, 2.5), dpi=600)\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "plt.rcParams['axes.edgecolor'] = 'black'\n",
    "plt.rcParams['axes.linewidth'] = 1\n",
    "\n",
    "\n",
    "# ---------------------- VRNN --------------------------------\n",
    "\n",
    "plot_stacked_kde(\n",
    "    vrnn_val_all_rel_errs, \n",
    "    ax=ax[0], \n",
    "    fontsize=8\n",
    ")\n",
    "\n",
    "# Prepare x and y values for VRNN validation (mean and median relative error)\n",
    "x_val = np.array(sorted(vrnn_val_stats.keys()))\n",
    "mean_rel_val = np.array([100 * vrnn_val_stats[k]['mean_rel_err'].item() \n",
    "                         for k in sorted(vrnn_val_stats.keys())])\n",
    "median_rel_val = np.array([100 * vrnn_val_stats[k]['median_rel_err'].item() \n",
    "                           for k in sorted(vrnn_val_stats.keys())])\n",
    "\n",
    "# Plot VRNN validation lines and markers\n",
    "ax[0].plot(x_val, mean_rel_val, color='red', linewidth=1, \n",
    "           label=\"validation - mean\")\n",
    "ax[0].plot(x_val, median_rel_val, color='red', linewidth=0.7, \n",
    "           label=\"validation - median\", linestyle='--')\n",
    "\n",
    "x_train = np.array(sorted(vrnn_train_stats.keys()))\n",
    "mean_rel_train = np.array([100 * vrnn_train_stats[k]['mean_rel_err'].item() \n",
    "                           for k in sorted(vrnn_train_stats.keys())])\n",
    "ax[0].scatter(x_train, mean_rel_train, color='red', edgecolor='black', \n",
    "              s=10, linewidth=0.3, label=\"train - mean\", zorder=10)\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_xlim(1e-2, 1e2)\n",
    "ax[0].set_ylim(0, 30)\n",
    "ax[0].legend(fontsize=8, loc='upper center')\n",
    "ax[0].grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "ax[0].set_box_aspect(1)\n",
    "ax[0].minorticks_off()\n",
    "ax[0].set_title('Voigt-Reuss net')\n",
    "\n",
    "\n",
    "# ---------------------- Vanilla ANN --------------------------------\n",
    "\n",
    "plot_stacked_kde(\n",
    "    vanilla_val_all_rel_errs, \n",
    "    ax=ax[1], \n",
    "    fontsize=8\n",
    ")\n",
    "\n",
    "# Prepare x and y values for Vanilla validation (mean and median relative error)\n",
    "x_val = np.array(sorted(vanilla_val_stats.keys()))\n",
    "mean_rel_val = np.array([100 * vanilla_val_stats[k]['mean_rel_err'].item() \n",
    "                         for k in sorted(vanilla_val_stats.keys())])\n",
    "median_rel_val = np.array([100 * vanilla_val_stats[k]['median_rel_err'].item() \n",
    "                           for k in sorted(vanilla_val_stats.keys())])\n",
    "\n",
    "# Plot Vanilla validation lines and markers\n",
    "ax[1].plot(x_val, mean_rel_val, color='lime', linewidth=1, \n",
    "           label=\"validation - mean\", linestyle='-')\n",
    "ax[1].plot(x_val, median_rel_val, color='lime', linewidth=0.7, \n",
    "           label=\"validation - median\", linestyle='--')\n",
    "\n",
    "x_train = np.array(sorted(vanilla_train_stats.keys()))\n",
    "mean_rel_train = np.array([100 * vanilla_train_stats[k]['mean_rel_err'].item() \n",
    "                           for k in sorted(vanilla_train_stats.keys())])\n",
    "ax[1].scatter(x_train, mean_rel_train, color='lime', edgecolor='black', \n",
    "              s=10, linewidth=0.3, label=\"train - mean\", zorder=10)\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_xlim(1e-2, 1e2)\n",
    "ax[1].set_ylim(0, 30)\n",
    "ax[1].legend(fontsize=8, loc='upper center')\n",
    "ax[1].grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "ax[1].set_box_aspect(1)\n",
    "ax[1].set_yticklabels([])\n",
    "ax[1].set_ylabel('')\n",
    "ax[1].minorticks_off()\n",
    "ax[1].set_title('Vanilla NN')\n",
    "\n",
    "\n",
    "# ---------------------- Compare VRNN and Vanilla ANN --------------------------------\n",
    "\n",
    "# Define the keys to use from the stats dictionaries\n",
    "stat_quantity = 'mean_rel_err'\n",
    "std_quantity = 'std_rel_err'\n",
    "\n",
    "# --- Vanilla ANN ---\n",
    "x_vanilla = np.array(sorted(vanilla_val_stats.keys()))\n",
    "mean_vals_vanilla = np.array([100 * vanilla_val_stats[k][stat_quantity].item() for k in sorted(vanilla_val_stats.keys())])\n",
    "std_vals_vanilla = np.array([100 * vanilla_val_stats[k][std_quantity].item() for k in sorted(vanilla_val_stats.keys())])\n",
    "\n",
    "upper_bound_vanilla = mean_vals_vanilla + std_vals_vanilla\n",
    "lower_bound_vanilla = mean_vals_vanilla - std_vals_vanilla\n",
    "\n",
    "ax[2].fill_between(x_vanilla, lower_bound_vanilla, upper_bound_vanilla, color='lime', alpha=0.2,\n",
    "                   label=fr\"Vanilla - $\\mu \\pm 1\\sigma$\", edgecolor='black')\n",
    "ax[2].plot(x_vanilla, mean_vals_vanilla, color='lime', linewidth=1,\n",
    "           )#label=\"Vanilla ANN - mean\", linestyle='-')\n",
    "\n",
    "x_train_vanilla = np.array(sorted(vanilla_train_stats.keys()))\n",
    "train_mean_vanilla = np.array([100 * vanilla_train_stats[k][stat_quantity].item() for k in sorted(vanilla_train_stats.keys())])\n",
    "# ax[2].scatter(x_train_vanilla, train_mean_vanilla, facecolors='lime', edgecolors='black', s=10,\n",
    "#               label=\"ANN train - mean\")\n",
    "\n",
    "# --- VRNN ---\n",
    "x_vrnn = np.array(sorted(vrnn_val_stats.keys()))\n",
    "mean_vals_vrnn = np.array([100 * vrnn_val_stats[k][stat_quantity].item() for k in sorted(vrnn_val_stats.keys())])\n",
    "std_vals_vrnn = np.array([100 * vrnn_val_stats[k][std_quantity].item() for k in sorted(vrnn_val_stats.keys())])\n",
    "\n",
    "upper_bound_vrnn = mean_vals_vrnn + std_vals_vrnn\n",
    "lower_bound_vrnn = mean_vals_vrnn - std_vals_vrnn\n",
    "\n",
    "ax[2].fill_between(x_vrnn, lower_bound_vrnn, upper_bound_vrnn, color='red', alpha=0.2,\n",
    "                   label=fr\"Voigt-Reuss - $\\mu \\pm 1\\sigma$\", edgecolor='black')\n",
    "ax[2].plot(x_vrnn, mean_vals_vrnn, color='red', linewidth=1,\n",
    "            )#label=\"Voigt-Reuss NN - mean\")\n",
    "\n",
    "x_train_vrnn = np.array(sorted(vrnn_train_stats.keys()))\n",
    "train_mean_vrnn = np.array([100 * vrnn_train_stats[k][stat_quantity].item() for k in sorted(vrnn_train_stats.keys())])\n",
    "# ax[2].scatter(x_train_vrnn, train_mean_vrnn, facecolors='red', edgecolors='black', s=10,\n",
    "#               label=\"VRNN training - mean\")\n",
    "\n",
    "ax[2].set_xscale('log')\n",
    "ax[2].legend(loc = 'upper center')\n",
    "ax[2].grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "ax[2].set_box_aspect(1)\n",
    "ax[2].set_xlim(1e-2, 1e2)\n",
    "ax[2].set_ylim(0, 30)\n",
    "ax[2].minorticks_off()\n",
    "ax[2].set_title('Comparison on validation set')\n",
    "ax[2].set_yticklabels([])\n",
    "ax[2].set_ylabel('')\n",
    "ax[2].set_xlabel(fr'Phase contrast $R \\;[-]$', fontsize=fontsize)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0.15)\n",
    "plt.show()\n",
    "\n",
    "# Save figure in high quality\n",
    "fig.savefig('../../overleaf/gfx/2D_thermal_error_comparison.png', dpi=600, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables\n",
    "fontsize = 8 \n",
    "nbins = 150  # Increased for smoother histograms\n",
    "linewidth = 1.0  # Increased for better visibility\n",
    "plt.style.use('seaborn-v0_8-paper')  # Use a clean, publication-style theme\n",
    "\n",
    "# Create figure with 2x4 tiles with adjusted size ratio\n",
    "fig, ax = plt.subplots(2, 4, figsize=[6.3, 3.5], dpi=300)\n",
    "\n",
    "# R values to plot with LaTeX formatting\n",
    "R_values = [1./100, 1./10, 10, 100]\n",
    "titles = [r'$R = 1/100$', r'$R = 1/10$', r'$R = 10 $', r'$R = 100$']\n",
    "labels_top = [r'$\\overline{\\kappa}_{11}$', r'$\\overline{\\kappa}_{22}$', r'$\\overline{\\kappa}_{12}$']\n",
    "labels_bottom = [r'$\\xi_{\\lambda1}$', r'$\\xi_{\\lambda2}$', r'$\\xi_{\\mathrm{q}1}$']\n",
    "\n",
    "# Define different colors for top and bottom rows\n",
    "colors_top = ['#1f77b4','#d62728', '#2ca02c' ]      # Blue, Red, Green\n",
    "colors_bottom = ['#9467bd', '#ff7f0e', '#17becf']    # Purple, Orange, Cyan\n",
    "\n",
    "# Plot histograms\n",
    "for i, (R, title) in enumerate(zip(R_values, titles)):\n",
    "    # Original data (top row)\n",
    "    for j, (label, color) in enumerate(zip(labels_top, colors_top)):\n",
    "        ax[0,i].hist(train_y[tmask(R), j].ravel().cpu(), bins=nbins, \n",
    "                    histtype=u'step', label=label, linewidth=linewidth,\n",
    "                    color=color, alpha=0.8)\n",
    "    ax[0,i].set_title(title, fontsize=fontsize, pad=8)\n",
    "    ax[0,i].grid(True, alpha=0.3, linewidth=0.5, linestyle='--')\n",
    "    # ax[0,i].set_yticklabels([])\n",
    "    ax[0,i].set_box_aspect(1.0)\n",
    "    # Keep all spines visible for box appearance\n",
    "    for spine in ax[0,i].spines.values():\n",
    "        spine.set_visible(True)\n",
    "    # ax[0,i].set_ylim(0, 10000)\n",
    "    # if i != 0:\n",
    "    #     ax[0,i].set_yticklabels([])\n",
    "\n",
    "    # Normalized data (bottom row)\n",
    "    for j, (label, color) in enumerate(zip(labels_bottom, colors_bottom)):\n",
    "        ax[1,i].hist(train_y_norm[tmask(R), j].ravel().cpu(), bins=nbins, \n",
    "                    histtype=u'step', label=label, linewidth=linewidth,\n",
    "                    color=color, alpha=0.8)\n",
    "    ax[1,i].set_title(title, fontsize=fontsize, pad=8)\n",
    "    ax[1,i].grid(True, alpha=0.4, linewidth=0.5, linestyle='--')\n",
    "    # ax[1,i].set_yticklabels([])\n",
    "    ax[1,i].set_box_aspect(1.0)\n",
    "    ax[1,i].set_xlim(0,1)\n",
    "    # Keep all spines visible for box appearance\n",
    "    for spine in ax[1,i].spines.values():\n",
    "        spine.set_visible(True)\n",
    "    # ax[1,i].set_ylim(0, 5000)\n",
    "    # if i != 0:\n",
    "    #     ax[1,i].set_yticklabels([])\n",
    "\n",
    "# Apply global fontsize and style\n",
    "for row in ax:\n",
    "    for a in row:\n",
    "        a.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "        a.tick_params(axis='both', which='minor', labelsize=fontsize)\n",
    "        a.xaxis.label.set_size(fontsize)\n",
    "        a.yaxis.label.set_size(fontsize)\n",
    "        # Add minor ticks for better precision\n",
    "        a.minorticks_on()\n",
    "\n",
    "# Create legends with better positioning and style\n",
    "legend1 = fig.legend(*ax[0,0].get_legend_handles_labels(), \n",
    "                    loc='center', bbox_to_anchor=(0.5, 0.50), \n",
    "                    ncol=3, fontsize=fontsize, frameon=True,\n",
    "                    edgecolor='black', fancybox=False)\n",
    "legend2 = fig.legend(*ax[1,0].get_legend_handles_labels(), \n",
    "                    loc='center', bbox_to_anchor=(0.5, -0.02), \n",
    "                    ncol=3, fontsize=fontsize, frameon=True,\n",
    "                    edgecolor='black', fancybox=False)\n",
    "\n",
    "# Adjust layout\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.475, wspace=0.4, bottom=0.08)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save the figure with high quality\n",
    "fig.savefig(\"../../overleaf/gfx/therm2d_histograms.pdf\", \n",
    "            bbox_inches='tight', \n",
    "            dpi=300,\n",
    "            metadata={'Creator': '', 'Producer': ''})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Set global fontsize\n",
    "fontsize = 8\n",
    "plt.style.use('seaborn-v0_8-paper')  # Clean, publication-style theme\n",
    "\n",
    "def plot_predictions_v3(ax, y, pred, idx=0, error_type='absolute_log', norm=None):\n",
    "    \"\"\"Create scatter plot with color-coded prediction errors.\"\"\"\n",
    "    y_sorted = y[:, idx]\n",
    "    pred_sorted = pred[:, idx]\n",
    "\n",
    "    # Calculate errors and determine color mapping\n",
    "    if error_type == 'absolute':\n",
    "        error_plt = np.abs((pred_sorted - y_sorted).cpu().numpy())\n",
    "        norm = plt.Normalize(vmin=0, vmax=2) if norm is None else norm\n",
    "    else:  # absolute_log\n",
    "        error_plt = np.abs((torch.log(np.abs(pred_sorted)) - torch.log(y_sorted)).cpu().numpy())\n",
    "        norm = plt.Normalize(vmin=0, vmax=2) if norm is None else norm\n",
    "\n",
    "    # Create scatter plot with viridis colormap\n",
    "    colors = cm.viridis(norm(error_plt))\n",
    "    ax.scatter(y_sorted.cpu().numpy(), \n",
    "              pred_sorted.cpu().numpy(), \n",
    "              color=colors, \n",
    "              marker='.',\n",
    "              s=5, \n",
    "              alpha=0.7)\n",
    "    \n",
    "    # Add diagonal reference line\n",
    "    lims = [y_sorted.min().item(), y_sorted.max().item()]\n",
    "    ax.plot(lims, lims, 'r--', alpha=0.8, linewidth=0.8)\n",
    "\n",
    "# Create figure and axes with standardized size\n",
    "fig, axs = plt.subplots(2, 3, figsize=[6.3, 3.05], dpi=300, sharex='col', squeeze=False)\n",
    "\n",
    "# Define norms for consistent color scaling\n",
    "norm_log = plt.Normalize(vmin=0, vmax=2)   # Columns 0 and 1\n",
    "norm_abs = plt.Normalize(vmin=0, vmax=12)  # Column 2\n",
    "\n",
    "# LaTeX labels for tensor components\n",
    "component_labels = [r\"$\\kappa_{11}$\", r\"$\\kappa_{22}$\", r\"$\\kappa_{12}$\"]\n",
    "\n",
    "# Filter validation data\n",
    "mask = val_x[:, -1] > 0\n",
    "models = [\n",
    "    (val_pred[mask].cpu(), \"VRNN\"),\n",
    "    (val_pred_vanilla[mask].cpu(), \"Vanilla\")\n",
    "]\n",
    "\n",
    "# Calculate R² scores for all models and components\n",
    "r2_scores = [[r2_score(val_y[mask][:, i].cpu(), pred[:, i].cpu()) \n",
    "              for i in range(3)] for pred, _ in models]\n",
    "\n",
    "# Create subplots\n",
    "for row, (pred, model_name) in enumerate(models):\n",
    "    for col in range(3):\n",
    "        ax = axs[row, col]\n",
    "        \n",
    "        # Plot with appropriate error metrics\n",
    "        error_type = 'absolute_log' if col < 2 else 'absolute'\n",
    "        norm = norm_log if col < 2 else norm_abs\n",
    "        plot_predictions_v3(ax, val_y[mask].cpu(), pred, idx=col, \n",
    "                          error_type=error_type, norm=norm)\n",
    "        \n",
    "        # Add R² score annotation\n",
    "        ax.text(0.05, 0.95, f\"$R^2 = {r2_scores[row][col]:.4f}$\", \n",
    "                transform=ax.transAxes, fontsize=fontsize, verticalalignment='top',\n",
    "                bbox=dict(facecolor='white', edgecolor='none', alpha=0.8, pad=2))\n",
    "        \n",
    "        # Add component label\n",
    "        ax.text(0.95, 0.05, component_labels[col], \n",
    "                transform=ax.transAxes, fontsize=fontsize, \n",
    "                horizontalalignment='right', verticalalignment='bottom',\n",
    "                bbox=dict(facecolor='white', edgecolor='none', alpha=0.8, pad=2))\n",
    "        \n",
    "        # Set axis scales and formatting\n",
    "        if col < 2:\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_yscale('log')\n",
    "\n",
    "        ax.tick_params(labelbottom=True)\n",
    "        ax.minorticks_on()\n",
    "        \n",
    "        ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.set_box_aspect(0.65)\n",
    "        \n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('')\n",
    "\n",
    "# Add colorbars at the bottom with adjusted positioning\n",
    "for col in range(3):\n",
    "    norm = norm_log if col < 2 else norm_abs\n",
    "    sm = plt.cm.ScalarMappable(cmap=cm.viridis, norm=norm)\n",
    "    # Create a new axis for colorbar below all plots\n",
    "    cax = fig.add_axes([0.1 + col*0.315, 0.02, 0.23, 0.02])\n",
    "    cbar = fig.colorbar(sm, cax=cax, orientation='horizontal')\n",
    "    cbar.ax.tick_params(labelsize=fontsize)\n",
    "    error_type = 'absolute_log' if col < 2 else 'absolute'\n",
    "    if col == 0:\n",
    "        error_label = r'$|\\log(\\widehat{\\overline{\\kappa}}_{11}) - \\log(\\overline{\\kappa}_{11})|$'\n",
    "    elif col == 1:\n",
    "        error_label = r'$|\\log(\\widehat{\\overline{\\kappa}}_{22} - \\log(\\overline{\\kappa}_{22})|$'\n",
    "    elif col == 2:\n",
    "        error_label = r'$|\\widehat{\\overline{\\kappa}}_{12} - \\overline{\\kappa}_{12}|$'\n",
    "    cbar.set_label(error_label, fontsize=fontsize)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.0, wspace=0.25)\n",
    "plt.show()\n",
    "\n",
    "# Save the figure with high quality\n",
    "fig.savefig(\"../../overleaf/gfx/therm2d_predictions_comparision_v2.png\", \n",
    "            bbox_inches='tight', \n",
    "            dpi=600,\n",
    "            metadata={'Creator': '', 'Producer': ''})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global settings\n",
    "fontsize = 8\n",
    "plt.rcParams.update({'font.size': fontsize})\n",
    "plt.style.use('seaborn-v0_8-paper')  # Clean, publication-style theme\n",
    "\n",
    "def plot_predictions_v2(ax, x, y, pred, phase_contrast, is_last_row=False):\n",
    "    # Create mask for the specified phase contrast\n",
    "    mask = x[:, -1] == phase_contrast\n",
    "    x_filtered = x[mask]\n",
    "    y_filtered = y[mask]\n",
    "    pred_filtered = pred[mask]\n",
    "    \n",
    "    # Process data for plotting\n",
    "    volume_fraction = x_filtered[:, 0].cpu().numpy()\n",
    "    y_matrix = torch.stack([torch.stack([y_filtered[:, 0], y_filtered[:, 2]], dim=-1),\n",
    "                          torch.stack([y_filtered[:, 2], y_filtered[:, 1]], dim=-1)], dim=-2)\n",
    "    pred_matrix = torch.stack([torch.stack([pred_filtered[:, 0], pred_filtered[:, 2]], dim=-1),\n",
    "                           torch.stack([pred_filtered[:, 2], pred_filtered[:, 1]], dim=-1)], dim=-2)\n",
    "    \n",
    "    # Compute eigenvalues\n",
    "    y_eigenvalues = torch.linalg.eigvals(y_matrix).real.cpu().numpy()\n",
    "    pred_eigenvalues = torch.linalg.eigvals(pred_matrix).real.cpu().numpy()\n",
    "    \n",
    "    # Generate bounds\n",
    "    vf = np.linspace(0, 1, 1500)\n",
    "    voigt_bound = vf - (vf - 1) / phase_contrast\n",
    "    reuss_bound = 1 / (phase_contrast + vf - phase_contrast * vf)\n",
    "    \n",
    "    # Plot data\n",
    "    vf_repeated = np.repeat(volume_fraction, 2)\n",
    "    stacked_y = y_eigenvalues.reshape(-1)\n",
    "    stacked_pred = pred_eigenvalues.reshape(-1)\n",
    "    \n",
    "    ax.fill_between(vf, np.flip(voigt_bound), y2=np.flip(reuss_bound), alpha=0.2, color='tab:blue')\n",
    "    ax.plot(vf, np.flip(voigt_bound), 'k--', linewidth=0.5, alpha=0.3, label='Voigt-Reuss bounds' if is_last_row else None)\n",
    "    ax.plot( vf, np.flip(reuss_bound), 'k--', linewidth=0.5, alpha=0.3)\n",
    "    \n",
    "    # compute the voigt and reuss bound for each entry of vf_repeated\n",
    "    voigt_bound = (1-vf_repeated) - ((1-vf_repeated) - 1) / phase_contrast\n",
    "    reuss_bound = 1 / (phase_contrast + (1-vf_repeated) - phase_contrast * (1-vf_repeated))\n",
    "    \n",
    "    if is_last_row:\n",
    "        ax.scatter(vf_repeated, stacked_y, s=1.5, color='royalblue',\n",
    "                edgecolor='black', linewidth=0.05, alpha=0.2)\n",
    "        ax.scatter([], [], s=3.0, color='royalblue', edgecolor='black', linewidth=0.05, alpha=1.0,\n",
    "                label=r'ground truth $\\lambda({\\overline{\\underline{\\underline{\\kappa}}}})$')\n",
    "    \n",
    "    \n",
    "    \n",
    "    violation_mask = (stacked_pred > voigt_bound) | (stacked_pred < reuss_bound)\n",
    "        \n",
    "    ax.scatter(vf_repeated[~violation_mask], stacked_pred[~violation_mask], s=1.5, color='limegreen',\n",
    "                edgecolor='black', linewidth=0.05, alpha=0.2)\n",
    "    ax.scatter([], [], s=3.0, color='limegreen', edgecolor='black', linewidth=0.05, alpha=1.0,\n",
    "               label=r'predicted $\\lambda(\\widehat{\\overline{\\underline{\\underline{\\kappa}}}})$' if is_last_row else None)\n",
    "    \n",
    "    \n",
    "    # Violations!\n",
    "    ax.scatter(vf_repeated[violation_mask], stacked_pred[violation_mask], s=3, color='red',\n",
    "               edgecolor='black', linewidth=0.05, alpha=1.0,\n",
    "              label=r'predicted $\\lambda(\\widehat{\\overline{\\underline{\\underline{\\kappa}}}})$ violation' if is_last_row else None)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots(3, 4, figsize=(6.3, 5.1), dpi=300)\n",
    "\n",
    "# Plot data\n",
    "contrasts = [1./75, 1./30, 30, 75]\n",
    "# contrasts = [1./75, 1./35, 15, 95]\n",
    "datasets = [val_pred, val_pred_vanilla, val_hill]\n",
    "\n",
    "for row, pred_data in enumerate(datasets):\n",
    "    for col, contrast in enumerate(contrasts):\n",
    "        plot_predictions_v2(ax[row, col], val_x, val_y, pred_data, contrast, is_last_row=(row==2))\n",
    "        if row == 0:\n",
    "            # Format first two columns as fractions, last two as regular numbers\n",
    "            if col < 2:\n",
    "                ax[row, col].set_title(fr'$R = 1/{int(1/contrast)}$', fontsize=fontsize)\n",
    "            else:\n",
    "                ax[row, col].set_title(fr'$R = {int(contrast)}$', fontsize=fontsize)\n",
    "        # if col == 0:\n",
    "        #     ax[row, col].set_ylabel('eigenvalues', fontsize=fontsize)\n",
    "        if row == 2:\n",
    "            ax[row, col].set_xlabel(fr'volume fraction $[-]$', fontsize=fontsize)\n",
    "        ax[row, col].grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "        ax[row, col].set_axisbelow(True)\n",
    "        ax[row, col].set_box_aspect(1.0)\n",
    "        ax[row, col].set_xlim(-0.1, 1.1)\n",
    "        ax[row, col].minorticks_on() # Add minor ticks\n",
    "        \n",
    "\n",
    "# Add single legend at the bottom\n",
    "handles, labels = ax[2, 0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.05), \n",
    "           ncol=4, fontsize=fontsize)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace = -0.2, bottom=0.025)  # Make room for legend\n",
    "\n",
    "# Save figure\n",
    "fig.savefig(\"../../overleaf/gfx/therm2d_predictions_VRbounds.png\", \n",
    "            bbox_inches='tight', \n",
    "            dpi=600,\n",
    "            metadata={'Creator': '', 'Producer': ''})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history_file = data_dir / 'Thermal2D_models/vrnn_therm2D_training_history_20250121_173200.out'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from matplotlib.ticker import LogLocator, NullFormatter\n",
    "\n",
    "# Initialize lists to store the values\n",
    "epochs, training_loss, validation_loss, learning_rates = [], [], [], []\n",
    "\n",
    "# Read the file\n",
    "with open(training_history_file, 'r') as file:\n",
    "    for line in file:\n",
    "        match = re.match(r'Epoch (\\d+): training loss ([\\d.]+), validation loss ([\\d.]+), learning rate ([\\d.e+-]+)', line)\n",
    "        if match:\n",
    "            epochs.append(int(match.group(1)))\n",
    "            training_loss.append(float(match.group(2)))\n",
    "            validation_loss.append(float(match.group(3)))\n",
    "            learning_rates.append(float(match.group(4)))\n",
    "\n",
    "# Hacky... scale training loss and validation loss by sqrt(2)\n",
    "training_loss = np.array(training_loss) / np.sqrt(2)\n",
    "validation_loss = np.array(validation_loss) / np.sqrt(2)\n",
    "\n",
    "# Increase font size for readability\n",
    "fontsize = 8\n",
    "linewidth = 0.5\n",
    "\n",
    "# Create a single figure with one axes\n",
    "fig, ax1 = plt.subplots(figsize=(6.3/2, 2.5), dpi=600)\n",
    "\n",
    "# Plot training and validation losses on the left y-axis with markers\n",
    "l1, = ax1.plot(epochs, training_loss, '-', label='Training Loss', linewidth=linewidth)# , color='blue')\n",
    "l2, = ax1.plot(epochs, validation_loss, '-', label='Validation Loss', linewidth=linewidth)# , color='red')\n",
    "ax1.set_xlabel('Epoch $[-]$', fontsize=fontsize)\n",
    "ax1.set_ylabel('Voigt-Reuss Normalized Loss $[-]$', fontsize=fontsize)\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylim(7e-3, 1)\n",
    "ax1.grid(which=\"both\", ls=\"--\", alpha=0.5, linewidth=0.3)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "ax1.legend(loc='lower left', fontsize=fontsize)\n",
    "\n",
    "# Add minor ticks to the left axis for a smoother log scale\n",
    "ax1.yaxis.set_minor_locator(LogLocator(subs='auto'))\n",
    "ax1.yaxis.set_minor_formatter(NullFormatter())\n",
    "\n",
    "# Create a twin axes to plot the learning rate decay on the right y-axis\n",
    "ax2 = ax1.twinx()\n",
    "l3, = ax2.plot(epochs, learning_rates, '-', color=\"grey\", label='Learning Rate', linewidth=linewidth)\n",
    "ax2.set_ylabel('Learning Rate $[-]$', fontsize=fontsize)\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_ylim(1e-5, 2e-1)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "ax2.legend(loc='upper right', fontsize=fontsize)\n",
    "\n",
    "ax2.set_xlim(-10, epochs[-1])\n",
    "# Apply consistent style and layout\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "plt.rcParams['axes.edgecolor'] = 'black'\n",
    "plt.rcParams['axes.linewidth'] = 1\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save the figure with high quality\n",
    "fig.savefig(\"../../overleaf/gfx/therm2d_vrnn_training_history.pdf\", \n",
    "            bbox_inches='tight', \n",
    "            dpi=600,\n",
    "            metadata={'Creator': '', 'Producer': ''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history_file = data_dir / 'Thermal2D_models/vann_therm2D_training_history_20250121_202555.out'\n",
    "\n",
    "# Initialize lists to store the values\n",
    "epochs, training_loss, validation_loss, learning_rates = [], [], [], []\n",
    "\n",
    "# Read the file\n",
    "with open(training_history_file, 'r') as file:\n",
    "    for line in file:\n",
    "        match = re.match(r'Epoch (\\d+): training loss ([\\d.]+), validation loss ([\\d.]+), learning rate ([\\d.e+-]+)', line)\n",
    "        if match:\n",
    "            epochs.append(int(match.group(1)))\n",
    "            training_loss.append(float(match.group(2)))\n",
    "            validation_loss.append(float(match.group(3)))\n",
    "            learning_rates.append(float(match.group(4)))\n",
    "\n",
    "# Hacky... scale training loss and validation loss by sqrt(2)\n",
    "training_loss = np.array(training_loss) / np.sqrt(2)\n",
    "validation_loss = np.array(validation_loss) / np.sqrt(2)\n",
    "\n",
    "# Increase font size for readability\n",
    "fontsize = 8\n",
    "linewidth = 0.5\n",
    "\n",
    "# Create a single figure with one axes\n",
    "fig, ax1 = plt.subplots(figsize=(6.3/2, 2.5), dpi=600)\n",
    "\n",
    "# Plot training and validation losses on the left y-axis with markers\n",
    "l1, = ax1.plot(epochs, training_loss, '-', label='Training Loss', linewidth=linewidth)# , color='blue')\n",
    "l2, = ax1.plot(epochs, validation_loss, '-', label='Validation Loss', linewidth=linewidth)# , color='red')\n",
    "ax1.set_xlabel('Epoch $[-]$', fontsize=fontsize)\n",
    "ax1.set_ylabel('MSE Loss', fontsize=fontsize)\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylim(2.5e-2, 3e3)\n",
    "ax1.grid(which=\"both\", ls=\"--\", alpha=0.5, linewidth=0.3)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "ax1.legend(loc='lower left', fontsize=fontsize)\n",
    "\n",
    "# Add minor ticks to the left axis for a smoother log scale\n",
    "ax1.yaxis.set_minor_locator(LogLocator(subs='auto'))\n",
    "ax1.yaxis.set_minor_formatter(NullFormatter())\n",
    "\n",
    "# Create a twin axes to plot the learning rate decay on the right y-axis\n",
    "ax2 = ax1.twinx()\n",
    "l3, = ax2.plot(epochs, learning_rates, '-', color=\"grey\", label='Learning Rate', linewidth=linewidth)\n",
    "ax2.set_ylabel('Learning Rate $[-]$', fontsize=fontsize)\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_ylim(1e-5, 2e-1)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "ax2.legend(loc='upper right', fontsize=fontsize)\n",
    "\n",
    "ax2.set_xlim(-10, epochs[-1])\n",
    "# Apply consistent style and layout\n",
    "plt.style.use('seaborn-v0_8-paper')\n",
    "plt.rcParams['axes.edgecolor'] = 'black'\n",
    "plt.rcParams['axes.linewidth'] = 1\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save the figure with high quality\n",
    "fig.savefig(\"../../overleaf/gfx/therm2d_vann_training_history.pdf\", \n",
    "            bbox_inches='tight', \n",
    "            dpi=600,\n",
    "            metadata={'Creator': '', 'Producer': ''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
